\newpage

\section[Day 4: Extrema]{ Extrema }

\subsection{ Taylor's Theorem }

    \begin{wtheorem}{Taylor's Theorem for one variable}{14cm}
        Let f: X $\subset$ $\mathbb{R}$ $\rightarrow$ $\mathbb{R}$
        be $C^{k+1}$.
        
        Then for a $\in$ X, the k-th order Taylor polynomial of f centered at a:

        \hspace{0.5cm}
        $p_k(x)$
        = $f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2
            + ... + \frac{f^{(k)}(a)}{k!}(x-a)^k$

        Then for h $>$ 0, there is a x $\in$ [a,a+h] such that:

        \hspace{0.5cm}
        f(a+h) = $p_k(a+h)$ + $\frac{f^{(n)}(x)}{(k+1)!}h^{k+1}$
    \end{wtheorem}

    \begin{proof}
        Let M be defined such that f(a+h) = $p_k(a+h)$ + $M(a+h-a)^{k+1}$.

        Let g(t) = f(t) - $p_k(t)$ - $M(t-a)^{k+1}$ for t $\in$ [a,a+h]. Then:

        \hspace{0.5cm}
        $g^{(k+1)}(t)$ = $f^{(k+1)}(t) - (k+1)!M$

        Since $p_k^{(i)}(a)$ = $f^{(i)}(a)$ for i = \{0,...,k\}, then:
        
        \hspace{0.5cm}
        $g^{(i)}(a)$ = $f^{(i)}(a)$ - $p_k^{(i)}(a)$
                        - $\frac{(k+1)!}{(k+1-i)!}M(a-a)^{k+1-i}$ = 0

        Since g(a+h) = 0 where f is differentiable so g is differentiable,
        then by the Mean Value Theorem, there is a $t_1$ $\in$ (0,h):

        \hspace{0.5cm}
        0 - 0
        = g(a+h) - g(a)
        = h*g'($a+t_1$)
        \hspace{0.5cm}
        $\Rightarrow$
        \hspace{0.5cm}
        g'($a+t_1$) = 0

        Since g' is differentiable, by the Mean Value Theorem,
        there is a $t_2$ $\in$ $(0,t_1)$:

        \hspace{0.5cm}
        0 - 0
        = g'($a+t_1$) - g'(a)
        = $t_1$*g''($a+t_2$)
        \hspace{0.5cm}
        $\Rightarrow$
        \hspace{0.5cm}
        g'($a+t_2$) = 0

        Repeating the process k+1 times, there is a $t_{k+1}$ $\in$ $(0,t_k)$:

        \hspace{0.5cm}
        0 - 0
        = $g^{(k)}(a+t_k)$ - $g^{(k)}(a)$
        = $t_k$*$g^{(k+1)}(a+t_{k+1})$
        \hspace{0.5cm}
        $\Rightarrow$
        \hspace{0.5cm}
        $g^{(k+1)}(a+t_{k+1})$ = 0

        Since $t_{k+1}$ $<$ $t_k$ $<$ ... $<$ $t_1$ $<$ h, then:

        \hspace{0.5cm}
        0 = $g^{(k+1)}(a+t_{k+1})$ = $f^{(k+1)}(a+t_{k+1}) - (k+1)!M$

        Thus, M = $\frac{f^{(k+1)}(a+t_{k+1})}{(k+1)!}$
        where $a+t_{k+1}$ $\in$ [a,a+h].
    \end{proof}

    \vspace{0.5cm}



    \begin{wtheorem}{Taylor's Theorem for multiple variables}{14cm}
        Let f: X $\subset$ $\mathbb{R}^n$ $\rightarrow$ $\mathbb{R}$
        be $C^2$. Then for a $\in$ X:

        \hspace{0.5cm}
        $p_k(x)$
        = $f(a)$
            + $\sum_{i=1}^n f_{x_i}(a)(x_i - a_i)$
            + $\frac{1}{2} \sum_{i,j=1}^n f_{x_ix_j}(a)(x_i - a_i)(x_j - a_j)$

            \hspace{2cm}
            + ...
            + $\frac{1}{k!} \sum_{i_1,...,i_k=1}^n
                f_{x_{i_1}...x_{i_k}}(a)(x_{i_1} - a_{i_1})...(x_{i_k} - a_{i_k})$

        Then:

        \hspace{0.5cm}
        f(x) = $p_k(x)$ + $R(a)$
        \hspace{1cm}
        where $\lim_{x \rightarrow a}$ $\frac{R(a)}{||x-a||}$ = 0
    \end{wtheorem}

    \newpage





\subsection{ Extrema }

    \begin{definition}{Local Extrema}{14cm}
        For f: X $\subset$ $\mathbb{R}^n$ $\rightarrow$ $\mathbb{R}$,
        let a $\in$ X.
        
        \hspace{0.5cm}
        f has a {\color{lblue} local minimum}
        at a if there is a $\delta > 0$ such that:

        \hspace{1cm}
        f(x) $\geq$ f(a) for all x $\in$ X where $||x-a|| < \delta$
        
        \hspace{0.5cm}
        f has a {\color{lblue} local maximum}
        at a if there is a $\delta > 0$ such that:

        \hspace{1cm}
        f(x) $\leq$ f(a) for all x $\in$ X where $||x-a|| < \delta$
    \end{definition}

    \vspace{0.5cm}



    \begin{wtheorem}{Local extrema have a derivative of 0}{14cm}
        For differentiable f: X $\subset$ $\mathbb{R}^n$ $\rightarrow$ $\mathbb{R}$,
        let a $\in$ X.

        If f has a local extrema at a, then Df(a) = 0.
    \end{wtheorem}

    \begin{proof}
        Let f have a local maximum at a. The proof for local minimum is
        analogous.

        For any i $\in$ \{1,...,n\}, let F(t) = f($a+te_i$).
        Since F: $\mathbb{R}$ $\rightarrow$ $\mathbb{R}$
        has a local maximum at F(0), then
        0 = F'(0) = $\frac{\partial f}{\partial x_i}(a)$.

        Since Df(a) =
        $
        \begin{bmatrix}
            \frac{\partial f}{\partial x_1}(a)
            & \frac{\partial f}{\partial x_2}(a)
            & ...
            & \frac{\partial f}{\partial x_n}(a)
        \end{bmatrix}
        $,
        then Df(a) = 0.
    \end{proof}

    \vspace{0.5cm}



    \begin{definition}{Critical Point and Saddle Point}{14cm}
        For f: X $\subset$ $\mathbb{R}^n$ $\rightarrow$ $\mathbb{R}$,
        let a $\in$ X.

        If Df(a) = 0 or undefined, then a is a {\color{lblue} critical point}.

        \vspace{0.3cm}

        Even if Df(a) = 0, f(a) might not be a local extrema
        since it might be a local maximum along some paths and
        a local minimum along other paths.
        For this type of ambiguity of extrema, a is defined as a
        {\color{lblue} saddle point}. 
    \end{definition}

    \vspace{0.5cm}



    \begin{wtheorem}{Second Derivative Test}{14cm}
        Let f: X $\subset$ $\mathbb{R}^2$ $\rightarrow$ $\mathbb{R}$
        be $C^2$.

        If a $\in$ X is a critical point of f, then:

        \begin{enumerate}[label=(\alph*), leftmargin=1cm, itemsep=0.1cm]
            \item If $f_{xx}(a)f_{yy}(a) - [f_{xy}(a)]^2$ $>$ 0 and
                $f_{xx}(a)$ $>$ 0, then a is a local minimum

            \item If $f_{xx}(a)f_{yy}(a) - [f_{xy}(a)]^2$ $>$ 0 and
                $f_{xx}(a)$ $<$ 0, then a is a local maximum

            \item If $f_{xx}(a)f_{yy}(a) - [f_{xy}(a)]^2$ $<$ 0,
                then a is saddle point
        \end{enumerate}
    \end{wtheorem}

    \vspace{0.5cm}



    \begin{definition}{Compactness}{14cm}
        Let set X $\subset$ $\mathbb{R}^n$.

        \vspace{0.3cm}

        A point x $\in$ X is a {\color{lblue} limit point}
        if for any $\delta > 0$:
        
        \hspace{0.5cm}
        The set of all p where $||p-x|| < \delta$
        contain a p $\in$ X where p $\not =$ x.

        X is closed if all limit point of X are in X.

        \vspace{0.3cm}

        X is {\color{lblue} bounded} if there is a M $\in$ $\mathbb{R}$
        such that for all x $\in$ X:

        \hspace{0.5cm}
        $||x||$ $<$ M

        \vspace{0.5cm}

        Then, X is {\color{lblue} compact} if X is closed and bounded.
    \end{definition}

    \vspace{0.5cm}



    \begin{wtheorem}{Extreme Value Theorem}{14cm}
        If X $\subset$ $\mathbb{R}^n$ is compact and
        f: X $\rightarrow$ $\mathbb{R}$ is continuous, then there are

        $x_{\text{min}},x_{\text{max}}$ $\in$ X such that for all x $\in$ X:

        \hspace{0.5cm}
        f($x_{\text{min}}$) $\leq$ f(x) $\leq$ f($x_{\text{max}}$)
    \end{wtheorem}

    \newpage





\subsection[ Lagrange Multipliers ]{ Lagrange Multipliers for Constrained Extrema }

    \begin{wtheorem}{Lagrange Multiplier: Optimization for one constraint}{14cm}
        Let f,g: X $\subset$ $\mathbb{R}^n$ $\rightarrow$ $\mathbb{R}$
        be $C^1$ and g(x) = c for constant c $\in$ $\mathbb{R}$.
        
        If f(x) has an extrema at $x_0$ where g($x_0$) = c and
        $\nabla g(x_0)$ $\not =$ 0, then there is a scalar $\lambda$ $\in$
        $\mathbb{R}$ such that:

        \hspace{0.5cm}
        $\nabla f(x_0)$ = $\lambda$ $\nabla g(x_0)$
    \end{wtheorem}

    \vspace{0.5cm}



    \begin{wtheorem}{Lagrange Multiplier: Optimization for multiple constraints}{14cm}
        Let f,$g_1,...,g_k$: X $\subset$ $\mathbb{R}^n$ $\rightarrow$ $\mathbb{R}$
        be $C^1$ where k $<$ n and each $g_i$(x) = $c_i$ for constants
        $c_i$ $\in$ $\mathbb{R}$ for i = \{1,...,k\}.
        
        If f(x) has an extrema at $x_0$ where each $g_i$($x_0$) = $c_i$ and
        $\nabla g_i(x_0)$ $\not =$ 0, then there are scalars
        $\lambda_1,...,\lambda_k$ $\in$ $\mathbb{R}$ such that:

        \hspace{0.5cm}
        $\nabla f(x_0)$ = $\lambda_1 \nabla g_1(x_0)
                            + \lambda_2 \nabla g_2(x_0)
                            + ... + \lambda_k \nabla g_k(x_0)$
    \end{wtheorem}





























